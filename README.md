# web-crawler

The `web-crawler` allows you to extract data from dynamic web pages in a powerful, jet convenient way. This is possible by using a headless browser, that injects your crawl-code into the running page-context.
It also provides a web-server, that serves crawl-results and static files to process and display the gathered information.

# Usage

TODO

# Install

1. Download [PhantomJS]()

  Get a built from their [download page](http://phantomjs.org/download.html).

2. Run your script

  ```bash
  /path/to/bin/phantomjs your-script.js
  ```

# API

TODO

# Documentation

TODO

# Dependencies

* [PhantomJS]() (tested with 1.9.7) : a headless browser

# License

The `web-crawler` is MIT licensed.

[PhantomJS]: http://phantomjs.org/