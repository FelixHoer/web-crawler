# web-crawler

The `web-crawler` allows you to extract data from dynamic web pages in a powerful, yet convenient way. This is possible by using [PhantomJS]() - a headless browser - which injects your crawl-code into running pages. To handle complex scenarios the sequence of operations is expressed as a state machine.

# Usage

TODO

# Install

1. Download [PhantomJS]()

  Get a built from their [download page](http://phantomjs.org/download.html).

2. Run your script

  ```bash
  /path/to/bin/phantomjs your-script.js
  ```

# API

TODO

# Documentation

TODO

# Dependencies

* [PhantomJS]() (tested with 1.9.7) : a headless browser

# License

The `web-crawler` is MIT licensed.

[PhantomJS]: http://phantomjs.org/
